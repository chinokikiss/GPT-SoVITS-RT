{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32fb6a16",
   "metadata": {},
   "source": [
    "# Model Initialization & Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bb00745",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-10 20:11:14,734 - TTS.py - INFO: Device: cuda:0\n",
      "2026-01-10 20:11:14,734 - TTS.py - INFO: Half: True, dtype: torch.float16\n",
      "2026-01-10 20:11:14,752 - TTS.py - INFO: Loaded language module: ja\n",
      "2026-01-10 20:11:15,574 - TTS.py - INFO: Loaded GPT model: pretrained_models/s1v3.ckpt\n",
      "2026-01-10 20:11:17,919 - TTS.py - INFO: Loaded SoVITS model: pretrained_models/v2Pro/s2Gv2ProPlus.pth\n",
      "2026-01-10 20:11:19,357 - TTS.py - INFO: Cached speaker audio: examples\\laffey.mp3\n",
      "2026-01-10 20:11:21,881 - TTS.py - INFO: Cached prompt audio: examples\\AnAn.ogg\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import sounddevice as sd\n",
    "from GPT_SoVITS_RT.TTS import TTS\n",
    "from tools import AudioStreamer, SubtitlesQueue\n",
    "\n",
    "\n",
    "tts = TTS(use_flash_attn=False)\n",
    "\n",
    "tts.init_language_module('ja')\n",
    "\n",
    "tts.load_gpt_model()\n",
    "\n",
    "tts.load_sovits_model()\n",
    "\n",
    "tts.cache_spk_audio(\"examples\\laffey.mp3\")\n",
    "\n",
    "tts.cache_prompt_audio({\n",
    "    \"audio\": \"examples\\AnAn.ogg\",\n",
    "    \"language\": \"ja\",\n",
    "    \"text\": \"ちが……ちがう。レイア、貴様は間違っている。\",\n",
    "})\n",
    "\n",
    "subtitlesqueue = SubtitlesQueue()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0760d72c",
   "metadata": {},
   "source": [
    "# Basic Text-to-Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77230908",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    text = input(\"infer text: \")\n",
    "    if text == \"\":\n",
    "        break\n",
    "\n",
    "    t = time.time()\n",
    "    \n",
    "    res = tts.infer(\n",
    "        spk_audio_path=\"examples\\laffey.mp3\",\n",
    "        prompt_audio_path=\"examples\\AnAn.ogg\",\n",
    "        prompt_audio_text=\"ちが……ちがう。レイア、貴様は間違っている。\",\n",
    "        prompt_audio_language=\"ja\",\n",
    "        text=text,\n",
    "        text_language=\"auto\",\n",
    "    )\n",
    "\n",
    "    audio_len_s = res[\"audio_len_s\"]\n",
    "    print(f\"RTF: {(time.time() - t) / audio_len_s:.2f}\")\n",
    "\n",
    "    subtitlesqueue.add(res[\"subtitles\"], text)\n",
    "\n",
    "    sd.play(res[\"audio_data\"], res[\"samplerate\"], blocking=True)\n",
    "\n",
    "    subtitlesqueue.add(None, None)\n",
    "\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de747727",
   "metadata": {},
   "source": [
    "# Voice Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fd55791",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-10 20:11:24,587 - TTS.py - INFO: Starting VC inference. Prompt audio: examples\\AnAn.ogg\n",
      "2026-01-10 20:11:24,589 - TTS.py - INFO: Using SoVITS model: pretrained_models/v2Pro/s2Gv2ProPlus.pth\n",
      "2026-01-10 20:11:25,836 - TTS.py - INFO: VC Inference complete. Generated 7.28s of audio.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'audio_data': array([ 2.0563602e-05, -2.0861626e-06, -7.9870224e-06, ...,\n",
      "        0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
      "      shape=(232960,), dtype=float32), 'samplerate': 32000, 'audio_len_s': 7.28, 'subtitles': [{'text': 'ち', 'start_s': 0, 'end_s': 0.4, 'orig_idx_start': 0, 'orig_idx_end': 1}, {'text': 'が', 'start_s': 0.4, 'end_s': 0.66, 'orig_idx_start': 1, 'orig_idx_end': 2}, {'text': '…', 'start_s': 0.66, 'end_s': 1.6600000000000001, 'orig_idx_start': 3, 'orig_idx_end': 4}, {'text': 'ち', 'start_s': 1.6600000000000001, 'end_s': 2.02, 'orig_idx_start': 4, 'orig_idx_end': 5}, {'text': 'が', 'start_s': 2.02, 'end_s': 2.2600000000000002, 'orig_idx_start': 5, 'orig_idx_end': 6}, {'text': 'う', 'start_s': 2.2600000000000002, 'end_s': 2.46, 'orig_idx_start': 6, 'orig_idx_end': 7}, {'text': '。', 'start_s': 2.46, 'end_s': 3.08, 'orig_idx_start': 7, 'orig_idx_end': 8}, {'text': 'レ', 'start_s': 3.08, 'end_s': 3.3200000000000003, 'orig_idx_start': 8, 'orig_idx_end': 9}, {'text': 'イ', 'start_s': 3.3200000000000003, 'end_s': 3.42, 'orig_idx_start': 9, 'orig_idx_end': 10}, {'text': 'ア', 'start_s': 3.42, 'end_s': 3.58, 'orig_idx_start': 10, 'orig_idx_end': 11}, {'text': '、', 'start_s': 3.58, 'end_s': 4.4, 'orig_idx_start': 11, 'orig_idx_end': 12}, {'text': '貴様', 'start_s': 4.4, 'end_s': 4.9, 'orig_idx_start': 12, 'orig_idx_end': 14}, {'text': 'は', 'start_s': 4.9, 'end_s': 5.04, 'orig_idx_start': 14, 'orig_idx_end': 15}, {'text': '間違', 'start_s': 5.04, 'end_s': 5.5, 'orig_idx_start': 15, 'orig_idx_end': 17}, {'text': 'っ', 'start_s': 5.5, 'end_s': 5.5600000000000005, 'orig_idx_start': 17, 'orig_idx_end': 18}, {'text': 'て', 'start_s': 5.5600000000000005, 'end_s': 5.74, 'orig_idx_start': 18, 'orig_idx_end': 19}, {'text': 'い', 'start_s': 5.74, 'end_s': 5.84, 'orig_idx_start': 19, 'orig_idx_end': 20}, {'text': 'る', 'start_s': 5.84, 'end_s': 6.04, 'orig_idx_start': 20, 'orig_idx_end': 21}, {'text': '。', 'start_s': 6.04, 'end_s': 7.28, 'orig_idx_start': 21, 'orig_idx_end': 22}]}\n"
     ]
    }
   ],
   "source": [
    "res = tts.infer_vc(\n",
    "    spk_audio_path=\"examples\\laffey.mp3\",\n",
    "    prompt_audio_path=\"examples\\AnAn.ogg\",\n",
    "    prompt_audio_text=\"ちが……ちがう。レイア、貴様は間違っている。\",\n",
    "    prompt_audio_language=\"ja\",\n",
    ")\n",
    "\n",
    "print(res)\n",
    "sd.play(res[\"audio_data\"], res[\"samplerate\"], blocking=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9541ce2f",
   "metadata": {},
   "source": [
    "# Streaming Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb416785",
   "metadata": {},
   "outputs": [],
   "source": [
    "streamer = AudioStreamer()\n",
    "\n",
    "stream = sd.OutputStream(\n",
    "    samplerate=32000, \n",
    "    channels=1, \n",
    "    callback=streamer.callback,\n",
    "    dtype='float32'\n",
    ")\n",
    "stream.start()\n",
    "\n",
    "while True:\n",
    "    text = input(\"infer text: \")\n",
    "    if text == \"\":\n",
    "        break\n",
    "    \n",
    "    generator = tts.infer_stream(\n",
    "        spk_audio_path=\"examples\\laffey.mp3\",\n",
    "        prompt_audio_path=\"examples\\AnAn.ogg\",\n",
    "        prompt_audio_text=\"ちが……ちがう。レイア、貴様は間違っている。\",\n",
    "        prompt_audio_language=\"ja\",\n",
    "        text=text,\n",
    "        text_language=\"auto\",\n",
    "        boost_first_chunk=True, # If True, reduces initial latency but may introduce noise in short audio; set to False for better stability.\n",
    "        debug=False,\n",
    "    )\n",
    "\n",
    "    t = time.time()\n",
    "    first_chunk = True\n",
    "\n",
    "    for audio_data in generator:\n",
    "        if first_chunk:\n",
    "            first_chunk = False\n",
    "            print(f\"TTFT: {int((time.time() - t) * 1000)}ms\")\n",
    "\n",
    "        subtitlesqueue.add(audio_data[\"new_subtitles\"], text)\n",
    "        streamer.put(audio_data[\"audio_data\"])\n",
    "\n",
    "    while not streamer.q.empty() or len(streamer.buffer) > 0:\n",
    "        sd.sleep(100)\n",
    "    \n",
    "    subtitlesqueue.add(None, None)\n",
    "    \n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
